{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving data with StatAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as cols\n",
    "\n",
    "import shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelhub import (\n",
    "    SentinelHubRequest, DataCollection, \n",
    "    SentinelHubStatistical, SentinelHubStatisticalDownloadClient,\n",
    "    CRS, BBox, Geometry, bbox_to_dimensions, \n",
    "    parse_time, parse_time_interval, MimeType\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once StatAPI reaches maturity, these functions will be available in `sh-py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_to_df(stat_data):\n",
    "    \"\"\" transform response from StatAPI into dataframe\"\"\"\n",
    "    df_data = defaultdict(list)\n",
    "\n",
    "    for single_data in stat_data['data']:\n",
    "        df_data['interval_from'].append(parse_time(single_data['interval']['from']).date())\n",
    "        df_data['interval_to'].append(parse_time(single_data['interval']['to']).date())\n",
    "        \n",
    "        for output_data in single_data['outputs'].keys():\n",
    "            single_band = len(single_data['outputs'][output_data]['bands']) == 1\n",
    "            for band_name, band_values in single_data['outputs'][output_data]['bands'].items():\n",
    "                for stat_name, value in band_values['stats'].items():\n",
    "                    col_name = f'{output_data}_{band_name}_{stat_name}'\n",
    "                    if stat_name == 'percentiles':\n",
    "                        for perc, perc_val in value.items():\n",
    "                            perc_col_name = f'{col_name}_{perc}'\n",
    "                            df_data[perc_col_name].append(perc_val)\n",
    "                    else:\n",
    "                        df_data[col_name].append(value)\n",
    "    \n",
    "    df = pd.DataFrame(df_data)\n",
    "    # df = df.astype({c:'float' for c in df.columns if any(n in c for n in ['mean','min','max','stDev','percentil'])})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_download_requests(gdf, data_folder=None):\n",
    "    \"\"\" function to create StatAPI request per each geometry in geopandas geoDataFrame \n",
    "    \n",
    "    :param: data_folder: specify a folder to cache the responses from SH service - particularly useful when testing\n",
    "    \"\"\"\n",
    "    \n",
    "    stat_requests = []\n",
    "    for row in gdf.itertuples():\n",
    "        req = SentinelHubStatistical(\n",
    "            aggregation=aggregation, \n",
    "            calculations=calculations, \n",
    "            input_data=[input_data], \n",
    "            geometry=Geometry(row.geometry, crs=CRS(gdf.crs.to_epsg())),\n",
    "            data_folder=data_folder\n",
    "        )\n",
    "        stat_requests.append(req)\n",
    "    \n",
    "    download_requests = [stat_request.download_list[0] for stat_request in stat_requests]\n",
    "    \n",
    "    if data_folder:\n",
    "        for download_request in download_requests:\n",
    "            download_request.save_response = True\n",
    "    \n",
    "    return download_requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch statistics using sh-py + StatAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evalscript to retrieve data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalscript = \"\"\"\n",
    "//VERSION=3\n",
    "function setup() {\n",
    "  return {\n",
    "    input: [{\n",
    "      bands: [\"B01\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B8A\", \"B09\", \"B10\", \"B11\", \"B12\", \"CLM\", \"CLP\", \"dataMask\"],\n",
    "      units: \"DN\"\n",
    "    }],\n",
    "    output: [\n",
    "      {\n",
    "        id: \"bands\",\n",
    "        bands: [\"B01\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B8A\", \"B09\", \"B10\", \"B11\", \"B12\"],\n",
    "        sampleType: \"UINT16\"\n",
    "      },\n",
    "      {\n",
    "        id: \"masks\",\n",
    "        bands: [\"CLM\"],\n",
    "        sampleType: \"UINT16\"\n",
    "      },\n",
    "      {\n",
    "        id: \"indices\",\n",
    "        bands: [\"NDVI\", \"NDVI_RE1\", \"NBSI\", \"CLP\"],\n",
    "        sampleType: \"UINT16\"\n",
    "      },\n",
    "      {\n",
    "        id: \"dataMask\",\n",
    "        bands: 1\n",
    "      }]\n",
    "  }\n",
    "}\n",
    "\n",
    "function evaluatePixel(samples) {\n",
    "    // Normalised Difference Vegetation Index and variation\n",
    "    let NDVI = index(samples.B08, samples.B04);\n",
    "    let NDVI_RE1 = index(samples.B08, samples.B05);\n",
    "\n",
    "    // Bare Soil Index \n",
    "    let NBSI = index((samples.B11 + samples.B04), (samples.B08 + samples.B02));\n",
    "    \n",
    "    // cloud probability normalized to 0..1\n",
    "    let CLP = samples.CLP/255.0;\n",
    "        \n",
    "    const f = 5000;\n",
    "    return {\n",
    "        bands: [samples.B01, samples.B02, samples.B03, samples.B04, samples.B05, samples.B06, \n",
    "                samples.B07, samples.B08, samples.B8A, samples.B09, samples.B10, samples.B11, samples.B12],\n",
    "        masks: [samples.CLM],\n",
    "        indices: [toUINT(NDVI, f), toUINT(NDVI_RE1, f), toUINT(NBSI, f), toUINT(CLP, f)],\n",
    "        dataMask: [samples.dataMask]\n",
    "    };\n",
    "}\n",
    "\n",
    "function toUINT(product, constant){\n",
    "  // Clamp the output to [-1, 10] and convert it to a UNIT16\n",
    "  // value that can be converted back to float later.\n",
    "  if (product < -1) {\n",
    "    product = -1;\n",
    "  } else if (product > 10) {\n",
    "    product = 10;\n",
    "  }\n",
    "  return Math.round(product * constant) + constant;\n",
    "}\n",
    "\n",
    "function feature_ratio(band_a, band_b, constant){\n",
    "  // Compute Band Ratio of the form A/B + constant.\n",
    "  return (band_a / band_b) + constant;\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = BBox(((407670.0, 5124960.0), (412270.0, 5128960.0)), crs=CRS.UTM_33N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval = ('2020-01-01','2020-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution=(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation = SentinelHubStatistical.aggregation(\n",
    "    evalscript=evalscript,\n",
    "    time_interval=('2020-01-01','2021-01-01'),\n",
    "    aggregation_interval='P1D',\n",
    "    size=bbox_to_dimensions(bbox, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = SentinelHubRequest.input_data(DataCollection.SENTINEL2_L1C, maxcc=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    We will request default statistics + [5,50,90]th percentiles for all outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculations = {\n",
    "    \"default\": {\n",
    "      \"statistics\": {\n",
    "        \"default\": {\n",
    "          \"percentiles\": {\n",
    "            \"k\": [5, 50, 95]\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = SentinelHubStatistical(\n",
    "    aggregation=aggregation, \n",
    "    calculations=calculations, \n",
    "    input_data=[input_data], \n",
    "    bbox=bbox\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = stats.get_data()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Beware that with StatAPI the response can contain errors for particular intervals. (With FIS, whole response failed if single timestamp failed.) This is how erroneous data looks like:\n",
    "</div>\n",
    "\n",
    "```javascript\n",
    "{'interval': {'from': '2020-12-21T00:00:00Z', 'to': '2020-12-22T00:00:00Z'}, 'error': {'type': 'EXECUTION_ERROR'}}\n",
    "{'interval': {'from': '2020-12-26T00:00:00Z', 'to': '2020-12-27T00:00:00Z'}, 'error': {'type': 'EXECUTION_ERROR'}}\n",
    "{'interval': {'from': '2020-12-31T00:00:00Z', 'to': '2021-01-01T00:00:00Z'}, 'error': {'type': 'EXECUTION_ERROR'}}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['data'][0]['interval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['data'][2]['outputs']['indices']['bands']['NDVI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Converting the response to `pandas` dataframe, we get:\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = stat_to_df(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion function to back to \"float\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "As our evalscript is requesting outputs as unsigned integers, we want to transform statistics back:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_res_df = res_df.copy()\n",
    "\n",
    "for index in [\"NDVI\", \"NDVI_RE1\", \"NBSI\", \"CLP\"]:\n",
    "    for stat in ['mean', 'min', 'max', 'stDev', 'percentiles_5.0', 'percentiles_50.0', 'percentiles_95.0']:\n",
    "        col = f'indices_{index}_{stat}'\n",
    "        if stat == 'stDev':\n",
    "            float_res_df[col] = float_res_df[col] / 5000.\n",
    "        else:\n",
    "            float_res_df[col] = (float_res_df[col] - 5000.) / 5000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Note: statistics for S-2 bands are still in DNs, so should be divided by 1.e4 to get to statistics for reflectances.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_res_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on all geometries from geodataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    To showcase how to run this on a large(r) number of geometries, using `sh-py` to do the multithreading etc., we've constructed a geoDataFrame with four polygons somewhere in Slovenia, over four different land covers: water, forest, agricultural fields and urban fabric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('../data/statapi_test.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    We will convert the geometries to UTM_33N coordinate reference system, as the Sentinel-2 tiles in Slovenia are originally in this UTM, but we could do the requests in WGS as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_utm = gdf.to_crs(epsg=32633)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_requests = to_download_requests(gdf_utm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = SentinelHubStatisticalDownloadClient()\n",
    "stat_data = client.download(download_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stat_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    We got back 4 responses, ordered in the same way as the rows in the `gdf_utm` are, so we can construct a full dataframe (adding land cover type) to the responses, and transforming the statistics for indices:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(stat_data[0]['data'][0]['outputs']['indices']['bands'].keys())\n",
    "statistics = ['min', 'max', 'mean', 'stDev']\n",
    "\n",
    "dfs = []\n",
    "for idx, stat in enumerate(stat_data):\n",
    "    df = stat_to_df(stat)\n",
    "    \n",
    "    for index in indices:\n",
    "        for stat in statistics:\n",
    "            col = f'indices_{index}_{stat}'\n",
    "            if stat == 'stDev':\n",
    "                df[col] = df[col] / 5000.\n",
    "            else:\n",
    "                df[col] = (df[col] - 5000.) / 5000.\n",
    "    \n",
    "    df['type'] = gdf_utm.iloc[idx].type\n",
    "    dfs.append(df)\n",
    "\n",
    "data = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "data.set_index('interval_from').groupby('type')['indices_NDVI_mean'].plot(ax=ax, legend=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that the four geometries are significantly different from each other, but the time series is very jagged. Let's use the information about the clouds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "#filtered = data[data.indices_CLP_mean<0.2]\n",
    "filtered = data[data.masks_CLM_mean<0.4]\n",
    "\n",
    "for idx, _type in enumerate(filtered.type.unique()):\n",
    "    series = filtered[filtered.type==_type]\n",
    "    series.plot(ax=ax, x='interval_from', y='indices_NDVI_mean', color=f'C{idx}', label=_type);\n",
    "    ax.fill_between(series.interval_from.values, series.indices_NDVI_mean-series.indices_NDVI_stDev, series.indices_NDVI_mean+series.indices_NDVI_stDev, color=f'C{idx}', alpha=0.3 );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
