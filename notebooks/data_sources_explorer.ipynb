{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-sources exploration using `eo-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows some examples on how to retrieve EO and non-EO data using `eo-learn`. \n",
    "\n",
    "The steps are as follow:\n",
    " * split area of interest into easy-to-process EOPatches\n",
    " * add Sentinel-2 imaging data\n",
    " * add vector and raster data from OSM\n",
    " * add Sentinel-1 imaging data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add generic packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import dates\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from shapely.geometry import Polygon, box, shape, mapping\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import overpass  # This one is not an eo-learn dependency and has to be additionally installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set path to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('..', 'data')\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`eo-learn` and `sentinelhub` imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eolearn.core import EOTask, EOPatch, FeatureType\n",
    "from eolearn.io import SentinelHubInputTask, SentinelHubEvalscriptTask\n",
    "from eolearn.geometry import VectorToRasterTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelhub import BBoxSplitter, BBox, CRS, DataCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split country into smaller bounding boxes <a id='splitter'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load shapefile of Denmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_filename = data_dir / 'denmark.geojson'\n",
    "country = gpd.read_file(country_filename)\n",
    "\n",
    "country.plot()\n",
    "country.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set CRS to UTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_crs = CRS.UTM_32N\n",
    "country = country.to_crs(country_crs.pyproj_crs())\n",
    "\n",
    "country.plot()\n",
    "country.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get size of country in pixels to decide number and size of bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_shape = country.geometry.values[-1]\n",
    "\n",
    "width_pix = int((country_shape.bounds[2] - country_shape.bounds[0]) / 10)\n",
    "height_pix = int((country_shape.bounds[3] - country_shape.bounds[1]) / 10)\n",
    "\n",
    "print(f'Dimension of the area is {width_pix} x {height_pix} pixels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split area into 45x35 boxes bounding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_splitter = BBoxSplitter([country_shape], country_crs, (45, 35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = [bbox.geometry for bbox in bbox_splitter.get_bbox_list()]\n",
    "bbox_list = bbox_splitter.get_bbox_list()\n",
    "idxs_x = [info['index_x'] for info in bbox_splitter.get_info_list()]\n",
    "idxs_y = [info['index_y'] for info in bbox_splitter.get_info_list()]\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    {'index_x':idxs_x, 'index_y':idxs_y},\n",
    "    geometry=[bbox.geometry for bbox in bbox_list],\n",
    "    crs=bbox_list[0].crs.pyproj_crs()\n",
    ")\n",
    "\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if bboxes have all same size, estimate offset\n",
    "xl, yl, xu, yu = gdf.geometry[0].bounds\n",
    "xoff, yoff = (xu - xl) / 3, (yu - yl) / 5\n",
    "\n",
    "# figure\n",
    "fig, ax = plt.subplots(figsize=(45,35))\n",
    "gdf.plot(ax=ax, facecolor='w', edgecolor='r', alpha=0.5, linewidth=2)\n",
    "country.plot(ax=ax, facecolor='w', edgecolor='b', alpha=0.5, linewidth=2.5)\n",
    "ax.set_title('Denmark tiled in a 45 x 35 grid');\n",
    "\n",
    "# add annotiation text\n",
    "fontdict = {'family': 'monospace', 'weight': 'normal', 'size': 14}\n",
    "for idx in gdf.index:\n",
    "    eop_name = '{0}x{1}'.format(gdf.index_x[idx], gdf.index_y[idx])\n",
    "    centroid, = list(gdf.geometry[idx].centroid.coords)\n",
    "    ax.text(centroid[0] - xoff, centroid[1] + yoff, str(idx), fontdict=fontdict)\n",
    "    ax.text(centroid[0] - xoff, centroid[1] - yoff, eop_name, fontdict=fontdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieve S2 L1C data <a id=\"sentinel-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_rgb_task = SentinelHubInputTask(\n",
    "    data_collection=DataCollection.SENTINEL2_L1C,\n",
    "    bands=['B04', 'B03', 'B02'],\n",
    "    bands_feature=(FeatureType.DATA, 'S2-RGB'),\n",
    "    additional_data=[(FeatureType.MASK, 'dataMask')],\n",
    "    resolution=(10, 10),\n",
    "    maxcc=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_evalscript = \"\"\"\n",
    "//VERSION=3\n",
    "\n",
    "function setup() {\n",
    "  return {\n",
    "    input: [\"B04\", \"B08\"],\n",
    "    output:[\n",
    "      {\n",
    "        id: \"ndvi\",\n",
    "        bands: 1,\n",
    "        sampleType: SampleType.FLOAT32\n",
    "      },\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "\n",
    "function evaluatePixel(sample) {\n",
    "  let ndvi = index(sample.B08, sample.B04);\n",
    "  return {\n",
    "    ndvi: [ndvi],\n",
    "  };\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "s2_ndvi_task = SentinelHubEvalscriptTask(\n",
    "    features=[(FeatureType.DATA, 'ndvi', 'NDVI')],\n",
    "    evalscript=ndvi_evalscript,\n",
    "    data_collection=DataCollection.SENTINEL2_L1C,\n",
    "    resolution=(10, 10),\n",
    "    maxcc=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval = ['2019-05-01','2019-09-01']\n",
    "idx = 436\n",
    "bbox = bbox_splitter.bbox_list[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download TRUE-COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch = s2_rgb_task.execute(bbox=bbox, time_interval=time_interval)\n",
    "\n",
    "eopatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch = s2_ndvi_task.execute(eopatch)\n",
    "\n",
    "eopatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch.timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot RGB of time frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_idx = 0\n",
    "\n",
    "rgb = eopatch.data['S2-RGB']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "ax.imshow(rgb[time_idx] * 3.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the median RGB values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "ax.imshow(np.median(rgb, axis=0).squeeze() * 3.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the median NDVI values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = eopatch.data['NDVI']\n",
    "median_ndvi = np.median(ndvi, axis=0).squeeze()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "im = ax.imshow(median_ndvi, cmap=plt.cm.YlGn)\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "fig.colorbar(im, cax=cax, orientation='vertical');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot temporal NDVI of a given location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_num = dates.date2num(eopatch.timestamp)\n",
    "dates_str = [timestamp.date().isoformat() for timestamp in eopatch.timestamp]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "ax.plot(dates_num, ndvi[:, 100, 550, :].squeeze(), 'g')\n",
    "\n",
    "ax.set_title('NDVI evolution')\n",
    "ax.set_xticks(dates_num);\n",
    "ax.set_xticklabels(dates_str, rotation=45, ha='right');\n",
    "ax.set_ylabel('NDVI');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Add information from OSM <a id=\"osm\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task is under-review and will soon make it into the released version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OsmInputTask(EOTask):\n",
    "    \"\"\" Use OpenStreetMap (OSM) data from an Overpass API as input to a VECTOR_TIMELESS feature.\n",
    "    \n",
    "    In case of timeouts or too many requests against the main Overpass endpoint, find additional\n",
    "    endpoints at see other options https://wiki.openstreetmap.org/wiki/Overpass_API#Public_Overpass_API_instances\n",
    "    \n",
    "    :param feature_name: EOPatch feature into which data will be imported\n",
    "    :type feature_name: (FeatureType, str)\n",
    "    :param query: Overpass API Querystring: https://wiki.openstreetmap.org/wiki/Overpass_API/Overpass_QL\n",
    "    :type query: str\n",
    "    :param polygonize: Whether or not to treat ways as polygons, defaults to True\n",
    "    :type polygonize: bool\n",
    "    :param overpass_params: Options to pass to the Overpass API constructor,\n",
    "        see: https://github.com/mvexel/overpass-api-python-wrapper#api-constructor\n",
    "    \"\"\"\n",
    "    def __init__(self, feature, query, polygonize=True, **overpass_params):\n",
    "        self.feature = feature\n",
    "        self.query = query\n",
    "        self.polygonize = polygonize\n",
    "        self.api = overpass.API(overpass_params)\n",
    "\n",
    "    def execute(self, eopatch):\n",
    "        \"\"\" Execute function which adds new VECTOR_TIMELESS layer to the EOPatch\n",
    "        \"\"\"\n",
    "        if not eopatch.bbox:\n",
    "            raise ValueError('Each EOPatch requires a bbox to fetch data')\n",
    "\n",
    "        # handling for various bounds variables\n",
    "        ll_bounds = eopatch.bbox.transform(CRS.WGS84)\n",
    "        clip_shape = box(*ll_bounds)\n",
    "        osm_bbox = tuple([*ll_bounds.reverse()])\n",
    "\n",
    "        # make the overpass request\n",
    "        response = self.api.get(f'{self.query}{osm_bbox}', verbosity='geom')\n",
    "\n",
    "        # clip geometries to bounding box\n",
    "        for feat in response['features']:\n",
    "            geom = Polygon(shape(feat['geometry']))\n",
    "            if self.polygonize:\n",
    "                geom = geom.convex_hull\n",
    "            clipped_geom = geom.intersection(clip_shape)\n",
    "            feat['geometry'] = mapping(clipped_geom)\n",
    "\n",
    "\n",
    "        # import to geopandas, transform and return\n",
    "        gdf = gpd.GeoDataFrame.from_features(response['features'])\n",
    "        gdf.crs = CRS.WGS84.pyproj_crs()\n",
    "        gdf = gdf.to_crs(eopatch.bbox.crs.pyproj_crs())\n",
    "        eopatch[self.feature] = gdf\n",
    "        \n",
    "        return eopatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_task = OsmInputTask(\n",
    "    (FeatureType.VECTOR_TIMELESS, 'residential'),\n",
    "    'way[\"landuse\"=\"residential\"]',\n",
    "    polygonize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch = osm_task.execute(eopatch)\n",
    "\n",
    "eopatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now burn the vector feature into a raster mask. \n",
    "\n",
    "The same task can be used to burn to raster any vector data stored in a shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterise = VectorToRasterTask(\n",
    "    (FeatureType.VECTOR_TIMELESS, 'residential'), \n",
    "    (FeatureType.MASK_TIMELESS, 'RESIDENTIAL_MASK'), \n",
    "    values=1,\n",
    "    raster_shape=(1007, 1002)\n",
    ")\n",
    "\n",
    "eopatch = rasterise.execute(eopatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_median = np.median(eopatch.data['S2-RGB'], axis=0).squeeze()\n",
    "residential_mask = eopatch.mask_timeless['RESIDENTIAL_MASK'].squeeze()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "ax.imshow(rgb_median * 3.5)\n",
    "ax.imshow(residential_mask, alpha=.3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks can be created to retrieve vector data from Geopedia, or from other geospatial databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Retrieve S1 data <a id=\"sentinel-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_iw_des_task = SentinelHubInputTask(\n",
    "    data_collection=DataCollection.SENTINEL1_IW_DES,\n",
    "    bands=['VV'],\n",
    "    bands_feature=(FeatureType.DATA, 'S1-IW-DES'),\n",
    "    additional_data=[(FeatureType.MASK, 'dataMask')],\n",
    "    resolution=(10, 10)\n",
    ")\n",
    "\n",
    "s1_iw_asc_task = SentinelHubInputTask(\n",
    "    data_collection=DataCollection.SENTINEL1_IW_ASC,\n",
    "    bands=['VV'],\n",
    "    bands_feature=(FeatureType.DATA, 'S1-IW-ASC'),\n",
    "    additional_data=[(FeatureType.MASK, 'dataMask')],\n",
    "    resolution=(10, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch_s1_des = s1_iw_des_task.execute(bbox=bbox, time_interval=['2019-07-01','2019-08-01'])\n",
    "\n",
    "eopatch_s1_des"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[VV-polarised Timescan Composite](https://github.com/ESA-PhiLab/OpenSarToolkit/blob/master/README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv_data = eopatch_s1_des.data['S1-IW-DES']\n",
    "vv_data[np.isnan(vv_data)] = 0\n",
    "\n",
    "vv_des_r = np.percentile(vv_data, 80, axis=0)\n",
    "vv_des_g = np.percentile(vv_data, 20, axis=0)\n",
    "vv_des_b = np.std(vv_data, axis=0)\n",
    "\n",
    "vv_rgb = np.concatenate((vv_des_r, vv_des_r, vv_des_b), axis=-1)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(vv_rgb);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch_s1_asc = s1_iw_asc_task.execute(bbox=bbox, time_interval=['2019-07-01','2019-08-01'])\n",
    "\n",
    "eopatch_s1_asc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv_data = eopatch_s1_asc.data['S1-IW-ASC']\n",
    "vv_data[np.isnan(vv_data)] = 0\n",
    "\n",
    "vv_des_r = np.percentile(vv_data, 80, axis=0)\n",
    "vv_des_g = np.percentile(vv_data, 20, axis=0)\n",
    "vv_des_b = np.std(vv_data, axis=0)\n",
    "\n",
    "vv_rgb = np.concatenate((vv_des_r, vv_des_r, vv_des_b), axis=-1)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(vv_rgb);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, Sentinel-2 L2A data can be added, as well as Digital Elevation data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
